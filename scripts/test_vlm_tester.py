#!/usr/bin/env python3
"""VLM Tester ã®å‹•ä½œãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Playwrightã§ç”»é¢ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã€VLMã§åˆ†æã™ã‚‹ã‚·ãƒŠãƒªã‚ªã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import asyncio
import os
from pathlib import Path

# Ollama URLã‚’è¨­å®šï¼ˆDockerå†…ï¼‰
os.environ["OLLAMA_BASE_URL"] = "http://hiveforge-dev-ollama:11434"


async def test_screen_capture():
    """ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®ãƒ†ã‚¹ãƒˆ"""
    from playwright.async_api import async_playwright

    from hiveforge.vlm_tester import ScreenCapture

    print("=" * 60)
    print("1. Playwright + ScreenCapture ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        # ã‚µãƒ³ãƒ—ãƒ«ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
        await page.goto("https://example.com")
        print(f"âœ“ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹: {page.url}")

        # ScreenCaptureã§ã‚­ãƒ£ãƒ—ãƒãƒ£
        capture = ScreenCapture(mode="playwright")
        capture.set_page(page)

        image_data = await capture.capture()
        print(f"âœ“ ã‚­ãƒ£ãƒ—ãƒãƒ£å–å¾—: {len(image_data)} bytes")

        # ä¿å­˜
        output_dir = Path("./test_captures")
        output_dir.mkdir(exist_ok=True)
        output_path = output_dir / "example_com.png"
        output_path.write_bytes(image_data)
        print(f"âœ“ ä¿å­˜: {output_path}")

        await browser.close()

    return image_data


async def test_local_analysis(image_data: bytes):
    """ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æã®ãƒ†ã‚¹ãƒˆï¼ˆOCR/Diffï¼‰"""
    from hiveforge.vlm_tester import AnalysisLevel, DiffAnalyzer, HybridAnalyzer

    print("\n" + "=" * 60)
    print("2. ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æãƒ†ã‚¹ãƒˆï¼ˆDiffï¼‰")
    print("=" * 60)

    # åŒä¸€ç”»åƒã®æ¯”è¼ƒ
    diff = DiffAnalyzer()
    result = await diff.compare(image_data, image_data)
    print(
        f"âœ“ åŒä¸€ç”»åƒæ¯”è¼ƒ: is_same={result.data['is_same']}, diff_ratio={result.data['diff_ratio']:.4f}"
    )

    # HybridAnalyzerï¼ˆLOCAL_ONLYãƒ¢ãƒ¼ãƒ‰ï¼‰
    print("\n" + "=" * 60)
    print("3. HybridAnalyzer (LOCAL_ONLY) ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    analyzer = HybridAnalyzer()
    result = await analyzer.analyze(
        image_data,
        "ã“ã®ç”»é¢ã‚’èª¬æ˜ã—ã¦ãã ã•ã„",
        level=AnalysisLevel.LOCAL_ONLY,
    )
    print(f"âœ“ åˆ†æãƒ¬ãƒ™ãƒ«: {result.analysis_level.value}")
    print(f"âœ“ ãƒ­ãƒ¼ã‚«ãƒ«çµæœ: {list(result.local_results.keys())}")
    print(f"âœ“ VLMãƒ¬ã‚¹ãƒãƒ³ã‚¹: {result.vlm_response}")


async def test_vlm_providers():
    """VLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ç¢ºèª"""
    from hiveforge.vlm_tester import AnthropicProvider, MultiProviderVLMClient, OllamaProvider

    print("\n" + "=" * 60)
    print("4. VLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼çŠ¶æ…‹ç¢ºèª")
    print("=" * 60)

    ollama = OllamaProvider(base_url="http://hiveforge-dev-ollama:11434")
    print(f"  Ollama available: {ollama.is_available()}")

    anthropic = AnthropicProvider()
    print(f"  Anthropic available: {anthropic.is_available()}")

    client = MultiProviderVLMClient()
    available = client.get_available_providers()
    print(f"  åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {available}")


async def test_ollama_vlm(image_data: bytes):
    """Ollama VLMã§ã®åˆ†æãƒ†ã‚¹ãƒˆ"""
    from hiveforge.vlm_tester import OllamaProvider

    print("\n" + "=" * 60)
    print("5. Ollama VLM åˆ†æãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    provider = OllamaProvider(base_url="http://hiveforge-dev-ollama:11434")

    if not provider.is_available():
        print("âš  OllamaãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return

    # ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
    import httpx

    async with httpx.AsyncClient() as client:
        response = await client.get("http://hiveforge-dev-ollama:11434/api/tags")
        models = response.json().get("models", [])
        model_names = [m["name"] for m in models]
        print(f"  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {model_names}")

        if not any("llava" in m for m in model_names):
            print("âš  llavaãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
            print("  ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™:")
            print('  curl http://hiveforge-dev-ollama:11434/api/pull -d \'{"name": "llava:7b"}\'')
            return

    print("  VLMåˆ†æã‚’å®Ÿè¡Œä¸­...")
    try:
        result = await provider.analyze(image_data, "ã“ã®ç”»é¢ã‚’æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„")
        print(f"âœ“ VLMãƒ¬ã‚¹ãƒãƒ³ã‚¹:\n{result.response[:500]}...")
    except Exception as e:
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")


async def test_action_executor():
    """ActionExecutorã®ãƒ†ã‚¹ãƒˆ"""
    from playwright.async_api import async_playwright

    from hiveforge.vlm_tester import ActionExecutor

    print("\n" + "=" * 60)
    print("6. ActionExecutor ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        await page.goto("https://example.com")

        executor = ActionExecutor(mode="playwright")
        executor.set_page(page)

        # ã‚¯ãƒªãƒƒã‚¯
        await executor.click(100, 100)
        print("âœ“ ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œ")

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        await executor.scroll(100, 100, delta_y=200)
        print("âœ“ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å®Ÿè¡Œ")

        # ã‚­ãƒ¼å…¥åŠ›
        await executor.press_key("escape")
        print("âœ“ Escapeã‚­ãƒ¼æŠ¼ä¸‹")

        await browser.close()


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸš€ VLM Tester å‹•ä½œãƒ†ã‚¹ãƒˆ\n")

    # 1. ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£
    image_data = await test_screen_capture()

    # 2. ãƒ­ãƒ¼ã‚«ãƒ«åˆ†æ
    await test_local_analysis(image_data)

    # 3. VLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç¢ºèª
    await test_vlm_providers()

    # 4. Ollama VLMåˆ†æ
    await test_ollama_vlm(image_data)

    # 5. ActionExecutor
    await test_action_executor()

    print("\n" + "=" * 60)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
