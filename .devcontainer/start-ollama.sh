#!/bin/bash
# OllamaËµ∑Âãï„Çπ„ÇØ„É™„Éó„ÉàÔºàGPUËá™ÂãïÊ§úÂá∫Ôºâ
# GPU„Åå„ÅÇ„Çå„Å∞GPUÁâà„ÄÅ„Å™„Åë„Çå„Å∞CPUÁâà„ÇíËµ∑Âãï

set -e

cd /workspace/ColonyForge

# Êó¢Â≠ò„ÅÆOllama„ÅåÂãï„ÅÑ„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
if curl -s http://ollama:11434/api/tags &>/dev/null || curl -s http://localhost:11434/api/tags &>/dev/null; then
    echo "‚úÖ Ollama is already running, skipping startup..."
    exit 0
fi

# GPUÊ§úÂá∫ÔºàË§áÊï∞„ÅÆÊñπÊ≥ï„ÇíË©¶Ë°åÔºâ
detect_gpu() {
    # Áí∞Â¢ÉÂ§âÊï∞„ÅßÊòéÁ§∫ÁöÑ„Å´ÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà
    if [ "$COLONYFORGE_GPU" = "nvidia" ]; then
        echo "  ‚Üí COLONYFORGE_GPU=nvidia „ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô"
        return 0
    fi

    # nvidia-smi „ÅåÂà©Áî®ÂèØËÉΩ„Åã„ÉÅ„Çß„ÉÉ„ÇØÔºàUbuntu WSL Docker „ÅÆÂ†¥ÂêàÔºâ
    if docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 true &>/dev/null 2>&1; then
        echo "  ‚Üí docker --gpus „Ç™„Éó„Ç∑„Éß„É≥„ÅåÂà©Áî®ÂèØËÉΩ"
        return 0
    fi

    # docker info „Åß nvidia „É©„É≥„Çø„Ç§„É†„ÇíÁ¢∫Ë™ç
    if docker info 2>/dev/null | grep -qi "nvidia"; then
        echo "  ‚Üí docker info „Åß nvidia „É©„É≥„Çø„Ç§„É†„ÇíÊ§úÂá∫"
        return 0
    fi

    echo "  ‚Üí GPUÊú™Ê§úÂá∫ÔºàCOLONYFORGE_GPU=nvidia „ÅßÂº∑Âà∂ÂèØËÉΩÔºâ"
    return 1
}

if detect_gpu; then
    echo "üöÄ GPU detected, starting Ollama with GPU support..."
    docker compose -f .devcontainer/docker-compose.dev.yml --profile gpu up -d ollama
else
    echo "üíª No GPU detected, starting Ollama in CPU mode..."
    docker compose -f .devcontainer/docker-compose.dev.yml --profile cpu up -d ollama-cpu
fi

# Ollama„ÅÆËµ∑Âãï„ÇíÂæÖÊ©ü
echo "‚è≥ Waiting for Ollama to be ready..."
for i in {1..30}; do
    if curl -s http://ollama:11434/api/tags &>/dev/null; then
        echo "‚úÖ Ollama is ready!"
        exit 0
    fi
    sleep 1
done

echo "‚ö†Ô∏è  Ollama may not be fully ready yet, but continuing..."
